{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "exFJkZt8GdEU"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "DTt1rNQsGoc0"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 1\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "total_train = 22400\n",
    "epochs_fine = 10\n",
    "num_folds = 5\n",
    "IMG_SHAPE = (IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos datos y etiquetas de memoria\n",
    "x_array = np.load('datos.npy')\n",
    "y_array = np.load('etiquetas.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "Ejecutando fold 1\n",
      "Ejecutando transfer learning\n",
      "175/175 [==============================] - 19s 97ms/step - loss: 1.9994 - accuracy: 0.4495\n",
      "Ejecutando fine tuning\n",
      "Epoch 1/10\n",
      "175/175 [==============================] - 99s 546ms/step - loss: 3.2021 - accuracy: 0.2897\n",
      "Epoch 2/10\n",
      "175/175 [==============================] - 93s 532ms/step - loss: 0.9150 - accuracy: 0.7566\n",
      "Epoch 3/10\n",
      "175/175 [==============================] - 97s 556ms/step - loss: 0.5485 - accuracy: 0.8554\n",
      "Epoch 4/10\n",
      "175/175 [==============================] - 97s 556ms/step - loss: 0.4042 - accuracy: 0.8868\n",
      "Epoch 5/10\n",
      "175/175 [==============================] - 94s 537ms/step - loss: 0.3213 - accuracy: 0.9102\n",
      "Epoch 6/10\n",
      "175/175 [==============================] - 95s 544ms/step - loss: 0.2555 - accuracy: 0.9243\n",
      "Epoch 7/10\n",
      "175/175 [==============================] - 97s 552ms/step - loss: 0.2149 - accuracy: 0.9383\n",
      "Epoch 8/10\n",
      "175/175 [==============================] - 94s 539ms/step - loss: 0.1876 - accuracy: 0.9435\n",
      "Epoch 9/10\n",
      "175/175 [==============================] - 95s 540ms/step - loss: 0.1582 - accuracy: 0.9563\n",
      "Epoch 10/10\n",
      "175/175 [==============================] - 95s 543ms/step - loss: 0.1372 - accuracy: 0.9598\n",
      "fold=1: perdida=2.6016950607299805 - accuracy=42.98214316368103%\n",
      "------------------------------------------------------------------\n",
      "Ejecutando fold 2\n",
      "Ejecutando transfer learning\n",
      "175/175 [==============================] - 22s 102ms/step - loss: 1.9781 - accuracy: 0.4556\n",
      "Ejecutando fine tuning\n",
      "Epoch 1/10\n",
      "175/175 [==============================] - 94s 510ms/step - loss: 3.5206 - accuracy: 0.2507\n",
      "Epoch 2/10\n",
      "175/175 [==============================] - 90s 512ms/step - loss: 0.9722 - accuracy: 0.7422\n",
      "Epoch 3/10\n",
      "175/175 [==============================] - 92s 525ms/step - loss: 0.5954 - accuracy: 0.8373\n",
      "Epoch 4/10\n",
      "175/175 [==============================] - 91s 518ms/step - loss: 0.4224 - accuracy: 0.8821\n",
      "Epoch 5/10\n",
      "175/175 [==============================] - 90s 512ms/step - loss: 0.3235 - accuracy: 0.9064\n",
      "Epoch 6/10\n",
      "175/175 [==============================] - 90s 515ms/step - loss: 0.2684 - accuracy: 0.9238\n",
      "Epoch 7/10\n",
      "175/175 [==============================] - 91s 522ms/step - loss: 0.2241 - accuracy: 0.9387\n",
      "Epoch 8/10\n",
      "175/175 [==============================] - 93s 529ms/step - loss: 0.1947 - accuracy: 0.9454\n",
      "Epoch 9/10\n",
      "175/175 [==============================] - 89s 510ms/step - loss: 0.1589 - accuracy: 0.9553\n",
      "Epoch 10/10\n",
      "175/175 [==============================] - 92s 525ms/step - loss: 0.1486 - accuracy: 0.9589\n",
      "fold=2: perdida=2.2844464778900146 - accuracy=43.19642782211304%\n",
      "------------------------------------------------------------------\n",
      "Ejecutando fold 3\n",
      "Ejecutando transfer learning\n",
      "175/175 [==============================] - 21s 107ms/step - loss: 2.0334 - accuracy: 0.4345\n",
      "Ejecutando fine tuning\n",
      "Epoch 1/10\n",
      "175/175 [==============================] - 113s 533ms/step - loss: 3.5744 - accuracy: 0.2486\n",
      "Epoch 2/10\n",
      "175/175 [==============================] - 93s 533ms/step - loss: 0.9598 - accuracy: 0.7472\n",
      "Epoch 3/10\n",
      "175/175 [==============================] - 95s 542ms/step - loss: 0.5960 - accuracy: 0.8360\n",
      "Epoch 4/10\n",
      "175/175 [==============================] - 94s 537ms/step - loss: 0.4271 - accuracy: 0.8821\n",
      "Epoch 5/10\n",
      "175/175 [==============================] - 95s 543ms/step - loss: 0.3266 - accuracy: 0.9117\n",
      "Epoch 6/10\n",
      "175/175 [==============================] - 97s 553ms/step - loss: 0.2783 - accuracy: 0.9196\n",
      "Epoch 7/10\n",
      "175/175 [==============================] - 92s 526ms/step - loss: 0.2314 - accuracy: 0.9350\n",
      "Epoch 8/10\n",
      "175/175 [==============================] - 95s 544ms/step - loss: 0.1991 - accuracy: 0.9439\n",
      "Epoch 9/10\n",
      "175/175 [==============================] - 94s 536ms/step - loss: 0.1687 - accuracy: 0.9539\n",
      "Epoch 10/10\n",
      "175/175 [==============================] - 95s 544ms/step - loss: 0.1399 - accuracy: 0.9620\n",
      "fold=3: perdida=2.343014717102051 - accuracy=40.69642722606659%\n",
      "------------------------------------------------------------------\n",
      "Ejecutando fold 4\n",
      "Ejecutando transfer learning\n",
      "175/175 [==============================] - 19s 97ms/step - loss: 2.0437 - accuracy: 0.4406\n",
      "Ejecutando fine tuning\n",
      "Epoch 1/10\n",
      "175/175 [==============================] - 101s 516ms/step - loss: 3.6036 - accuracy: 0.2499\n",
      "Epoch 2/10\n",
      "175/175 [==============================] - 91s 519ms/step - loss: 0.9794 - accuracy: 0.7359\n",
      "Epoch 3/10\n",
      "175/175 [==============================] - 93s 534ms/step - loss: 0.5892 - accuracy: 0.8427\n",
      "Epoch 4/10\n",
      "175/175 [==============================] - 93s 534ms/step - loss: 0.4221 - accuracy: 0.8818\n",
      "Epoch 5/10\n",
      "175/175 [==============================] - 92s 528ms/step - loss: 0.3281 - accuracy: 0.9069\n",
      "Epoch 6/10\n",
      "175/175 [==============================] - 92s 528ms/step - loss: 0.2722 - accuracy: 0.9233\n",
      "Epoch 7/10\n",
      "175/175 [==============================] - 94s 538ms/step - loss: 0.2226 - accuracy: 0.9384\n",
      "Epoch 8/10\n",
      "175/175 [==============================] - 93s 534ms/step - loss: 0.1992 - accuracy: 0.9427\n",
      "Epoch 9/10\n",
      "175/175 [==============================] - 94s 536ms/step - loss: 0.1629 - accuracy: 0.9554\n",
      "Epoch 10/10\n",
      "175/175 [==============================] - 93s 532ms/step - loss: 0.1388 - accuracy: 0.9622\n",
      "fold=4: perdida=2.309835910797119 - accuracy=40.48214256763458%\n",
      "------------------------------------------------------------------\n",
      "Ejecutando fold 5\n",
      "Ejecutando transfer learning\n",
      "175/175 [==============================] - 19s 95ms/step - loss: 2.0074 - accuracy: 0.4491\n",
      "Ejecutando fine tuning\n",
      "Epoch 1/10\n",
      "175/175 [==============================] - 96s 520ms/step - loss: 3.2997 - accuracy: 0.2700\n",
      "Epoch 2/10\n",
      "175/175 [==============================] - 93s 529ms/step - loss: 0.9169 - accuracy: 0.7586\n",
      "Epoch 3/10\n",
      "175/175 [==============================] - 93s 531ms/step - loss: 0.5638 - accuracy: 0.8498\n",
      "Epoch 4/10\n",
      "175/175 [==============================] - 92s 528ms/step - loss: 0.4104 - accuracy: 0.8864\n",
      "Epoch 5/10\n",
      "175/175 [==============================] - 93s 534ms/step - loss: 0.3202 - accuracy: 0.9128\n",
      "Epoch 6/10\n",
      "175/175 [==============================] - 93s 529ms/step - loss: 0.2630 - accuracy: 0.9271\n",
      "Epoch 7/10\n",
      "175/175 [==============================] - 94s 534ms/step - loss: 0.2174 - accuracy: 0.9384\n",
      "Epoch 8/10\n",
      "175/175 [==============================] - 93s 529ms/step - loss: 0.1831 - accuracy: 0.9492\n",
      "Epoch 9/10\n",
      "175/175 [==============================] - 92s 528ms/step - loss: 0.1584 - accuracy: 0.9547\n",
      "Epoch 10/10\n",
      "175/175 [==============================] - 92s 526ms/step - loss: 0.1392 - accuracy: 0.9633\n",
      "fold=5: perdida=2.38970947265625 - accuracy=42.38256812095642%\n"
     ]
    }
   ],
   "source": [
    "# Creamos la clase que nos va a dividir los datos\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# Variable para almacenar el número de fold por el que vamos\n",
    "num_fold = 1\n",
    "\n",
    "# Variables donde almacenar la accuracy y la pérdida de cada fold\n",
    "accuracies = []\n",
    "losses = []\n",
    "\n",
    "# Realizamos la validacion cruzada\n",
    "for train, test in kfold.split(x_array, y_array): \n",
    "    # Obtenemos datos y etiquetas de entrenamiento\n",
    "    datos_train = x_array[train]\n",
    "    etiquetas_train = y_array[train]\n",
    "    \n",
    "    # Obtenemos datos y etiquetas de test\n",
    "    datos_test = x_array[test]\n",
    "    etiquetas_test = y_array[test]\n",
    "\n",
    "    # Create el modelo base\n",
    "    base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                                   include_top=False,\n",
    "                                                   weights='imagenet')\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "    prediction_layer = tf.keras.layers.Dense(28, activation='softmax')\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "      base_model,\n",
    "      global_average_layer,\n",
    "      prediction_layer\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    print('------------------------------------------------------------------')\n",
    "    print(f'Ejecutando fold {num_fold}')\n",
    "    \n",
    "    print(f'Ejecutando transfer learning')\n",
    "    \n",
    "    history = model.fit(\n",
    "        x=datos_train, \n",
    "        y=etiquetas_train, \n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs)\n",
    "    \n",
    "    base_model.trainable = True\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(1e-5),  \n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    print(f'Ejecutando fine tuning')\n",
    "\n",
    "    history = model.fit(\n",
    "        x=datos_train, \n",
    "        y=etiquetas_train, \n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs_fine)\n",
    "\n",
    "    # Evaluamos el modelo con los datos de test\n",
    "    scores = model.evaluate(datos_test, etiquetas_test, verbose=0)\n",
    "    \n",
    "    print(f'fold={num_fold}: perdida={scores[0]} - accuracy={scores[1]*100}%')\n",
    "    \n",
    "    accuracies.append(scores[1] * 100)\n",
    "    losses.append(scores[0])\n",
    "    \n",
    "    K.clear_session()\n",
    "\n",
    "    # Pasamos el siguiente fold\n",
    "    num_fold = num_fold + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------\n",
      "Fold 1: Loss=2.6016950607299805 - Accuracy=42.98214316368103%\n",
      "-------------------------------------------------------------------\n",
      "Fold 2: Loss=2.2844464778900146 - Accuracy=43.19642782211304%\n",
      "-------------------------------------------------------------------\n",
      "Fold 3: Loss=2.343014717102051 - Accuracy=40.69642722606659%\n",
      "-------------------------------------------------------------------\n",
      "Fold 4: Loss=2.309835910797119 - Accuracy=40.48214256763458%\n",
      "-------------------------------------------------------------------\n",
      "Fold 5: Loss=2.38970947265625 - Accuracy=42.38256812095642%\n",
      "-------------------------------------------------------------------\n",
      "Final: Loss=2.385740327835083 - Accuracy=41.94794178009033% (+- 1.142982586506918)\n"
     ]
    }
   ],
   "source": [
    "# Mostramos los resultados\n",
    "for i in range(len(accuracies)):\n",
    "    print('-------------------------------------------------------------------')\n",
    "    print(f'Fold {i+1}: Loss={losses[i]} - Accuracy={accuracies[i]}%')\n",
    "    \n",
    "print('-------------------------------------------------------------------')\n",
    "print(f'Final: Loss={np.mean(losses)} - Accuracy={np.mean(accuracies)}% (+- {np.std(accuracies)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'modeloFinalFineTuning.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = new_model.predict(x_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.52496536e-05, 4.26581028e-05, 4.83288964e-10, 1.47379169e-05,\n",
       "       2.89587064e-07, 1.05237192e-03, 3.27298039e-04, 1.22638352e-01,\n",
       "       2.08580673e-06, 4.47910224e-06, 8.05806984e-12, 1.22808362e-03,\n",
       "       8.22458730e-07, 1.09876972e-04, 8.63652458e-05, 8.70499253e-01,\n",
       "       4.27346735e-04, 1.09955067e-06, 4.80066582e-08, 1.93857122e-05,\n",
       "       1.19256205e-08, 5.21227194e-04, 2.02319073e-03, 6.92204367e-06,\n",
       "       1.17451680e-04, 6.79058721e-04, 1.11104591e-05, 1.51252694e-04],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = 5\n",
    "np.argmax(pred[num]) == y_array[num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: loss of 0.09432641416788101; accuracy of 96.910160779953%\n"
     ]
    }
   ],
   "source": [
    "new_scores = new_model.evaluate(datos_test, etiquetas_test, verbose=0)\n",
    "print(f'Score: {new_model.metrics_names[0]} of {new_scores[0]}; {new_model.metrics_names[1]} of {new_scores[1]*100}%')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TFG2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
